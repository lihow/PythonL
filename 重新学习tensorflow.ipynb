{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重新学习tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.tensorflow是通过会话sess来执行运算  \n",
    "sess.run（函数）执行函数，sess.run(变量)打印变量  \n",
    "2.variable来保存张量，使用前需要执行initialize_all_variables()来初始化  \n",
    "使用此变量可以保存权重和偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型时，需要使用变量(Variables)保存和更新参数。Variables是包含张量(tensor)的内存缓冲。变量必须要先被初始化(initialize)，而且可以在训练时和训练后保存(save)到磁盘中。之后可以再恢复(restore)保存的变量值来训练和测试模型  \n",
    "在运行模型中其他操作之前，必须先对变量进行初始化。  \n",
    "使用tf.global_variables_initializer()添加一个op来运行初始化。要在完全构建完模型后，在一个对话(Session)中运行它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.constant(value, dtype=None, shape=None, name=’Const’) \n",
    "创建一个常量tensor，按照给出value来赋值，可以用shape来指定其形状。value可以是一个数，也可以是一个list。 如果是一个数，那么这个常亮中所有值的按该数来赋值。 如果是list,那么len(value)一定要小于等于shape展开后的长度。赋值时，先将value中的值逐个存入。不够的部分，则全部存入value的最后一个值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.assign  \n",
    "通过将 \"value\" 赋给 \"ref\" 来更新 \"ref\"。\n",
    "此操作输出在赋值后保留新值 \"ref\" 的张量。这使得更易于链接需要使用重置值的操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.cast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.cast(x, dtype, name=None)  \n",
    "参数\n",
    "x：输入\n",
    "dtype：转换目标类型\n",
    "name：名称"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此函数可以理解为形参，用于定义过程，在执行的时候再赋具体的值  \n",
    "tf.placeholder(dtype, shape=None, name=None)   \n",
    "dtype：数据类型。常用的是tf.float32,tf.float64等数值类型  \n",
    "shape：数据形状。默认是None，就是一维值，也可以是多维，比如[2,3], [None, 3]表示列是3，行不定  \n",
    "name：名称。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.train.slice_input_producer  \n",
    "tf.train.slice_input_producer(tensor_list, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None)  \n",
    "**tf.train.slice_input_producer是一个tensor生成器，作用是按照设定，每次从一个tensor列表中按顺序或者随机抽取出一个tensor放入文件名队列**  \n",
    "第一个参数 tensor_list：包含一系列tensor的列表，表中tensor的第一维度的值必须相等，即个数必须相等，有多少个图像，就应该有多少个对应的标签。  \n",
    "第二个参数num_epochs: 可选参数，是一个整数值，代表迭代的次数，如果设置 num_epochs=None,生成器可以无限次遍历tensor列表，如果设置为   num_epochs=N，生成器只能遍历tensor列表N次。  \n",
    "第三个参数shuffle： bool类型，设置是否打乱样本的顺序。一般情况下，如果shuffle=True，生成的样本顺序就被打乱了，在批处理的时候不需要再次打乱样  本，使用 tf.train.batch函数就可以了;如果shuffle=False,就需要在批处理时候使用 tf.train.shuffle_batch函数打乱样本。  \n",
    "第四个参数seed: 可选的整数，是生成随机数的种子，在第三个参数设置为shuffle=True的情况下才有用。  \n",
    "第五个参数capacity：设置tensor列表的容量。  \n",
    "第六个参数shared_name：可选参数，如果设置一个‘shared_name’，则在不同的上下文环境（Session）中可以通过这个名字共享生成的tensor。  \n",
    "第七个参数name：可选，设置操作的名称。  \n",
    "**tf.train.slice_input_producer定义了样本放入文件名队列的方式，包括迭代次数，是否乱序等，要真正将文件放入文件名队列，还需要调用tf.train.start_queue_runners 函数来启动执行文件名队列填充的线程，之后计算单元才可以把数据读出来，否则文件名队列为空的，计算单元就会处于一直等待状态，导致系统阻塞**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.read_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.read_file(filename,name=None)  \n",
    "filename: A Tensor of type string.  \n",
    "name: A name for the operation (optional).  \n",
    "example:  \n",
    "    image_value = tf.read_file('test/a.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.image.decode_jpeg  \n",
    "Decode a JPEG-encoded image to a uint8 tensor.  \n",
    "### tf.image.resize_image_with_crop_or_pad  \n",
    "剪裁或填充处理，会根据原图像的尺寸和指定的目标图像的尺寸选择剪裁还是填充，如果原图像尺寸大于目标图像尺寸，则在中心位置剪裁，反之则用黑色像素填充。  \n",
    "### tf.image.per_image_standardization(image)  \n",
    "此函数的运算过程是将整幅图片标准化（不是归一化），加速神经网络的训练, 标准化处理可以使得不同的特征具有相同的尺度（Scale),对图像进行标准化：减去均值并除以像素的方差  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.train.batch  \n",
    "tf.train.batch([example, label], batch_size=batch_size, capacity=capacity)：[example, label]表示样本和样本标签，这个可以是一个样本和一个样本标签，batch_size是返回的一个batch样本集的样本个数。capacity是队列中的容量。这主要是按顺序组合成一个batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reshape  \n",
    "tf.reshape(tensor,shape,name=None)  \n",
    "函数的作用是将tensor变换为参数shape形式，其中的shape为一个列表形式  \n",
    "```\n",
    "tensor = tf.constant([1, 2, 3, 4, 5, 6, 7,8])\n",
    "tensorReshape = tf.reshape(tensor,[2,4])  \n",
    "print(sess.run(tensorReshape))\n",
    " \n",
    "[[1 2 3 4]\n",
    " [5 6 7 8]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.train.Coordinator  \n",
    "使用 tf.train.Coordinator()来创建一个线程管理器（协调器）对象 \n",
    "**\n",
    "1. 调用 tf.train.slice_input_producer，从 本地文件里抽取tensor，准备放入Filename Queue（文件名队列）中;\n",
    "2. 调用 tf.train.batch，从文件名队列中提取tensor，使用单个或多个线程，准备放入文件队列;\n",
    "3. 调用 tf.train.Coordinator() 来创建一个线程协调器，用来管理之后在Session中启动的所有线程;\n",
    "4. 调用tf.train.start_queue_runners, 启动入队线程，由多个或单个线程，按照设定规则，把文件读入Filename Queue中。函数返回线程ID的列表，一般情况下，系统有多少个核，就会启动多少个入队线程（入队具体使用多少个线程在tf.train.batch中定义）;\n",
    "5. 文件从 Filename Queue中读入内存队列的操作不用手动执行，由tf自动完成;\n",
    "6. 调用sess.run 来启动数据出列和执行计算;\n",
    "7. 使用 coord.should_stop()来查询是否应该终止所有线程，当文件队列（queue）中的所有文件都已经读取出列的时候，会抛出一个 OutofRangeError 的异常，这时候就应该停止Sesson中的所有线程了;\n",
    "8. 使用coord.request_stop()来发出终止所有线程的命令，使用coord.join(threads)把线程加入主线程，等待threads结束。\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sess.run() 中的feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feed_dict的作用是给使用placeholder创建出来的tensor赋值   \n",
    "```x = tf.placeholder(tf.string)  \n",
    "with tf.Session() as sess:  \n",
    "    output = sess.run(x, feed_dict={x: 'Hello World'})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reduce_mean  \n",
    "计算张量的各个维度上的元素的平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reduce_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce_sum( input_tensor, axis=None, keep_dims=False, name=None, reduction_indices=None)  \n",
    "说明：reduce_sum() 就是求和，由于求和的对象是tensor，所以是沿着tensor的某些维度求和。函数名中加了reduce是表示求和后会降维，当然可以通过设置参数来保证不降维，但是默认就是要降维的  \n",
    "参数解释：1）input_tensor：输入的张量。2）axis：沿着哪个维度求和。对于二维的input_tensor张量，0表示按列求和，1表示按行求和，[0, 1]表示先按列求和再按行求和。3）keep_dims：默认值为Flase，表示默认要降维。若设为True，则不降维。4）name：名字。5）reduction_indices：默认值是None，即把input_tensor降到 0维，也就是一个数。对于2维input_tensor，reduction_indices=0时，按列；reduction_indices=1时，按行。注意，reduction_indices与axis不能同时设置  \n",
    "``\n",
    "x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "tf.reduce_sum(x, 0)  # 对 tensor 的 0 级进行求和，[1,1,1] + [1,1,1] =  [2, 2, 2]\n",
    "tf.reduce_sum(x, 1)  # 对 tensor 的 1 级进行仇和，[1+1+1, 1+1+1] = [3, 3]\n",
    "tf.reduce_sum(x, 1, keep_dims=True)  # 对第 1 级进行求和，但不降维, [[3], [3]]\n",
    "tf.reduce_sum(x, [0, 1])  # 0 级和 1级都要求和，6\n",
    "tf.reduce_sum(x)  # 因为 x 只有 2 级，所以结果同上一个，6\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.random_normal | tf.truncated_normal | tf.random_uniform  \n",
    "tf.random_normal(shape,mean=0.0,stddev=1.0,dtype=tf.float32,seed=None,name=None) \n",
    "tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None) \n",
    "tf.random_uniform(shape,minval=0,maxval=None,dtype=tf.float32,seed=None,name=None) \n",
    "这几个都是用于生成随机数tensor的。尺寸是shape \n",
    "random_normal: 正太分布随机数，均值mean,标准差stddev \n",
    "truncated_normal:截断正态分布随机数，均值mean,标准差stddev,不过只保留[mean-2*stddev,mean+2*stddev]范围内的随机数 \n",
    "random_uniform:均匀分布随机数，范围为[minval,maxval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化器最后其实就是各种对于梯度下降算法的优化   \n",
    "优化器（optimizers）类的基类。这个类定义了在训练模型的时候添加一个操作的API。你基本上不会直接使用这个类，但是你会用到他的子类比如GradientDescentOptimizer, AdagradOptimizer, MomentumOptimizer.等等这些。  \n",
    "f.train.GradientDescentOptimizer 梯度下降算法的优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一些imort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. from __future__ import print_function  \n",
    "这是 python 2 的概念,Python提供了__future__模块，把下一个新版本的特性导入到当前版本，于是我们就可以在当前版本中测试一些新版本的特性,显然 python 3 对于 python2 就是 future了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf5 example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.56615776] [ 0.07958651]\n",
      "20 [ 0.20517485] [ 0.24692354]\n",
      "40 [ 0.12403726] [ 0.2878696]\n",
      "60 [ 0.10549362] [ 0.29722765]\n",
      "80 [ 0.10125554] [ 0.29936641]\n",
      "100 [ 0.10028695] [ 0.2998552]\n",
      "120 [ 0.10006559] [ 0.2999669]\n",
      "140 [ 0.10001498] [ 0.29999244]\n",
      "160 [ 0.10000344] [ 0.29999828]\n",
      "180 [ 0.10000079] [ 0.29999962]\n",
      "200 [ 0.10000017] [ 0.29999992]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# create data\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data*0.1 + 0.3\n",
    "\n",
    "### create tensorflow structure start ###\n",
    "Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "#训练模型时，需要使用变量(Variables)保存和更新参数\n",
    "biases = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "y = Weights*x_data + biases\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "### create tensorflow structure end ###\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)          # Very important\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(Weights), sess.run(biases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf 6 example 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n",
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "matrix1 = tf.constant([[3, 3]])\n",
    "matrix2 = tf.constant([[2],\n",
    "                       [2]])\n",
    "product = tf.matmul(matrix1, matrix2)  # matrix multiply np.dot(m1, m2)\n",
    "\n",
    "# method 1\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "sess.close()\n",
    "\n",
    "# method 2\n",
    "with tf.Session() as sess:\n",
    "    result2 = sess.run(product)\n",
    "    print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf 7 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    " \"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "state = tf.Variable(0, name='counter')\n",
    "#print(state.name)\n",
    "one = tf.constant(1)\n",
    "\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "init = tf.initialize_all_variables()  # must have if define variable\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tf 8 feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "ouput = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(ouput, feed_dict={input1: [7.], input2: [2.]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf 10 def_add_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf 11 build_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Lenovo\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0.0771344\n",
      "0.00979138\n",
      "0.00837933\n",
      "0.00806125\n",
      "0.00780825\n",
      "0.00757348\n",
      "0.0073305\n",
      "0.00706471\n",
      "0.0067982\n",
      "0.00654175\n",
      "0.00627767\n",
      "0.00602692\n",
      "0.00579069\n",
      "0.00557295\n",
      "0.00537355\n",
      "0.00518675\n",
      "0.00500312\n",
      "0.00482633\n",
      "0.00466048\n",
      "0.00451485\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "# Make up some real data\n",
    "x_data = np.linspace(-1,1,300)[:, np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                     reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# important step\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        # to see the step improvement\n",
    "        print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tf 11 plot_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA5Rk9fVDBLXgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c607c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "# Make up some real data\n",
    "x_data = np.linspace(-1, 1, 300)[:, np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "##plt.scatter(x_data, y_data)\n",
    "##plt.show()\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "# important step\n",
    "init = tf.initialize_all_variables()\n",
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# plot the real data\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(x_data, y_data)\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        # to visualize the result and improvement\n",
    "        try:\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction, feed_dict={xs: x_data})\n",
    "        # plot the prediction\n",
    "        lines = ax.plot(x_data, prediction_value, 'r-' q, lw=5)\n",
    "        plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf 16 classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# number 1 to 10 data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None,):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b,)\n",
    "    return outputs\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return result\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add output layer\n",
    "prediction = add_layer(xs, 784, 10,  activation_function=tf.nn.softmax)\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))       # loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "# important step\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(\n",
    "            mnist.test.images, mnist.test.labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
